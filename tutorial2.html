<!doctype html>
<html lang="en">

  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

    <!-- Mathjax -->
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  <title>AI Safety &middot; Tutorial 2</title>
  </head>

  <body>
    <!-- Navbar -->
    <nav class="navbar navbar-expand-sm bg-dark navbar-dark">
      <a class="navbar-brand" href="index.html">AI Safety</a>
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="nav-link active" href="overview.html">Overview</a>
        </li>
        <li class="nav-item">
          <a class="nav-link active" href="paper.html">Paper</a>
        </li>
        <li class="nav-item dropdown active">
          <a class="nav-link dropdown-toggle" href="#" id="navbardrop" data-toggle="dropdown">
            Tutorials
          </a>
          <div class="dropdown-menu">
            <a class="dropdown-item" href="tutorial0.html">Tutorial Overview</a>
            <a class="dropdown-item" href="tutorial1.html">1. Seldonian algorithm review</a>
            <a class="dropdown-item disabled" href="tutorial2.html">2. Example problem</a>
            <a class="dropdown-item" href="tutorial3.html">3. A simple Seldonian algorithm</a>
            <hr>
            <h6 class="dropdown-header text-primary"><b>C++</b></h6>
            <a class="dropdown-item" href="tutorial4cpp.html">&nbsp;&nbsp;&nbsp;4. Coding environment setup</a>
            <a class="dropdown-item" href="tutorial5cpp.html">&nbsp;&nbsp;&nbsp;5. Safety test</a>
            <a class="dropdown-item" href="tutorial6cpp.html">&nbsp;&nbsp;&nbsp;6. Candidate selection</a>
            <a class="dropdown-item" href="tutorial7cpp.html">&nbsp;&nbsp;&nbsp;7. Plotting</a>
            <h6 class="dropdown-header text-success"><b>Python</b></h6>
            <a class="dropdown-item" href="tutorial4py.html">&nbsp;&nbsp;&nbsp;4. Coding environment setup</a>
            <a class="dropdown-item" href="tutorial5py.html">&nbsp;&nbsp;&nbsp;5. Safety test</a>
            <a class="dropdown-item" href="tutorial6py.html">&nbsp;&nbsp;&nbsp;6. Candidate selection</a>
            <a class="dropdown-item" href="tutorial7py.html">&nbsp;&nbsp;&nbsp;7. Plotting</a>
            <hr>
            <a class="dropdown-item" href="tutorial8.html">8. Advanced Topics</a>
          </div>
        </li>
        <li class="nav-item">
          <a class="nav-link active" href="code.html">Code</a>
        </li>
        <li class="nav-item active">
          <a class="nav-link" href="about.html">About Us</a>
        </li>
      </ul>
      <!--<ul class="navbar-nav">
        <li class="nav-item active">
          <a class="nav-link" href="donate.html">Donate</a>
        </li>
      </ul>-->
    </nav>

    <!-- Begin Content -->
    <div class="container">
      <div class="card bg-light mt-2">
        <div class="card-body">
          <h2>Simple Problem: Hello Seldonian Machine Learning!</h2>
          <p align="justify">
            We begin with a simple problem that can be solved using a Seldonian algorithm. This is the <a href="https://en.wikipedia.org/wiki/%22Hello,_World!%22_program">Hello World!</a> of Seldonian machine learning. When first solving this problem, we will hold off on providing a slick interface, and focus on the core computational components of a Seldonian algorithm. 
          </p>
          <p align="justify">
            In this tutorial we will consider a <em>regression</em> problem. Let \(X \in \mathbb R\) and \(Y \in \mathbb R\) be two dependent random variables. Our goal is to estimate \(Y\) given \(X\), based on training data consisting of \(m\) independent and identically distributed samples, \(\{(X_i,Y_i)\}_{i=1}^m\). In this example we construct synthetic data where the inputs \(X\) come from a standard normal distribution and where the outputs \(Y\)are equal to the inputs, plus noise with a standard normal distribution:
            $$
            X \sim N(0,1)\quad\text{ and } \quad Y \sim N(X,1),
            $$
            where \(N(\mu,\sigma^2)\) denotes the normal distribution with mean \(\mu\) and variance \(\sigma^2\). Notice that Seldonian algorithms will <em>not</em> know the distributions of \(X\) and \(Y\) in advance.
          </p>
          <p align="justify">
            The plot below shows 50,000 points sampled in this way:
          </p>
          <div class="container">
            <div class="row">
              <div class="col-md-4"></div>
              <div class="col-md-4">
                <img src="images/samples.png" class="img-fluid mx-auto d-block rounded shadow p-3 mb-5 bg-white" alt="Data samples">
                <figcaption class="figure-caption">Matlab source code: [<a href="code/PlotDataDistribution.m">link</a>].</figcaption>
              </div>
              <div class="col-md-4"></div>
            </div>
          </div>
          <p align="justify">
            Let \(\Theta = \mathbb R^2\) and let \(\hat y(X,\theta)=\theta_1 X + \theta_2\) be the estimate of \(Y\) given \(X\) and \(\theta\). The <em>mean squared error</em> (MSE) of a solution \(\theta\) is 
            $$
            \operatorname{MSE}(\theta)=\mathbf E\left [ (\hat y(X,\theta)-Y)^2\right ].
            $$
            In our example, the goal of the designer of the algorithm is to construct an algorithm that
            <ul>
              <li> minimizes the mean squared error (or, equivalently, maximizes the <em>negative</em> of the MSE). Here, the expectation is over the solutions produced by the algorithm when evaluated over the possible datasets in \(\mathcal D\); and</li>
              <li> ensures that, with probability at least 0.9, the mean squared error of its predictions is below 2.0; and that with probability at least 0.9, the mean squared error if its predictions is above 1.25. </li>
            </ul>
          </p>

          <p align="justify">
            In other words, the designer wishes to create an algorithm \(a\) that maximizes \(f(a)\) (where \(f(a)\) is the negative MSE) and that satisfies \(n=2\) behavioral constraints, \(g_1\) and \(g_2\), with probabilities \(1-\delta_1\) and \(1-\delta_2\), respectively. The behavioral constraints, then, are
            
            <ul>
              <li>\(g_1(\theta)=\operatorname{MSE}(\theta)-2.0\) and \(\delta_1=0.1\)</li>
              <li>\(g_2(\theta)=1.25 - \operatorname{MSE}(\theta)\) and \(\delta_2=0.1\)</li>
            </ul>
          </p>

          <p align="justify">

          Because the algorithm does not have prior access to the distributions of \(X\) and \(Y\), it cannot compute MSE(\(\theta\)) analytically for any given candidate solution \(\theta\). More generally, because we do not know the user's application&mdash;to which datasets he or she will apply the algorithm&mdash;we cannot compute the value of \(f(a)\) for any \(a\). We can, however, define a <em>sample objective function</em>, \(\hat f\), that estimates the utility of a given algorithm, \(a\), when \(a\) returns the solution \(\theta\) given input data \(D\). In our particular example, the sample objective function \(\hat f\) is the <em>sample mean squared error</em> of a given candidate solution \(\theta\):
            $$
            \hat f(\theta,D)=-\frac{1}{n}\sum_{i=1}^n (\hat y(X_i,\theta)-Y_i)^2. 
            $$
            Furthermore, notice that the behavioral constraints, \(g_1\) and \(g_2\), are also defined in terms of the MSE, which cannot be computed exactly. This means that \(g_1\) and \(g_2\) cannot be computed analytically either. Instead of requiring the user to produce \(g_1\) and \(g_2\), we allow the user to specify functions \(\hat g_i\) that provide unbiased estimates of each corresponding constraint \(g_i\). In particular, each function \(\hat g_i(\theta,D)\) uses data to compute a vector of independent and identically distributed (i.i.d.) unbiased estimates of \(g_i(\theta)\). Let \(g_{i,j}(\theta,D)\) be the \(j^\text{th}\) unbiased estimate returned by \(\hat g_i(\theta,D)\). In our regression application, we compute these unbiased estimates of the behavioral constraints as follows:
            <ul>
              <li>\(\hat g_{1,j}(\theta,D) = (\hat y(X_j,\theta)-Y_j)^2-2.0\), and</li>
              <li>\(\hat g_{2,j}(\theta,D) = 1.25-(\hat y(X_j,\theta)-Y_j)^2\)</li>
            </ul>

            Notice that because \(g_{i,j}(\theta,D)\) are i.i.d. unbiased estimates of \(g_i\), for every \(i\) and \(j\), it follows that \(g_i(\theta)=\mathbf E[\hat g_{i,j}(\theta,D)]\).
          </p>
        </div>
      </div>

      <div class="card bg-light mt-2">
        <div class="card-body">
          <h2>Recap</h2>

          <p align="justify">
            <ul>
              <li>A Seldonian algorithm \(a\) maximizes an objective function \(f\) and ensures that all behavioral constraints are satisfied.</li>
              <li>In this example we wish to create a linear regression algorithm that guarantees with probabiliy \(0.9\) that the MSE of its predictions is below \(2.0\) and with probability \(0.9\) that the MSE of its predictions is above \(1.25\)</li>
              <li>By <a href="https://en.wikipedia.org/wiki/Boole%27s_inequality">Boole's inequality</a>, this implies that with probability \(0.8\) the MSE of its predictions is in the interval \([1.25,2.0]\).</li>
              <li>In our example, \(f(a)\) is the negative MSE of the solution that algorithm \(a\) will return for the user's application. We do not know the value of \(f(a)\) for any \(a\), as we do not know in advance the user's application when creating the algorithm.</li> 
              <li>Instead, we will require the user to provide a <em>sample objective function</em>, \(\hat f:\Theta \times \mathcal D \to \mathbb R\), such that \(\hat f(\theta,D)\) is an estimate of the utility of any algorithm that returns the solution \(\theta\) when given input data \(D\). In this example, \(\hat f\) is the <em>sample mean squared error</em>: \(\hat f(\theta,D)=\frac{1}{n}\sum_{i=1}^n (\hat y(X_i,\theta)-Y_i)^2\).</li>
              <li>We will test our algorithm on a simple data set where the inputs come from a standard normal distribution and the outputs are equal to the inputs, plus noise with a standard normal distribution.</li>
              <li>We will begin by using an interface that makes <em>creating</em> the Seldonian algorithm easier. Our initial interface will require the user to provide functions \(\hat g_i\). Later we will focus on interfaces that make it easier for users to <em>define and identify</em> undesirable behavior.</li>
              <li>Our example application was constructed to be simple, and yet also to test the ability of a Seldonian algorithm to handle behavioral constraints that may be in conflict with the objective function. Notice, for instance, that the solution that minimizes the MSE will violate the second behavioral constraint.</li>
              <li>Once we have created a quasi-Seldonian algorithm for this problem, we will discuss how to create simpler interfaces to specify undesirable behavior and how to apply these ideas to the general regression and classification settings.</li>
            </ul>
          </p>

          <p align="justify">
            
          </p>


        </div>
      </div>

      <div class="card-body">
        <a href="tutorial1.html" type="button" class="btn btn-outline-primary">Previous: Seldonian algorithm review</a>
        <a href="tutorial3.html" type="button" class="btn btn-primary float-right">Next: A simple Seldonian algorithm</a>
      </div>

      <hr class="my-4">
    </div>

    
    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  </body>
</html>